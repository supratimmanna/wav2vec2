{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Union\n",
    "\n",
    "import datasets\n",
    "import torch\n",
    "# from accelerate import Accelerator\n",
    "# from accelerate.logging import get_logger\n",
    "from datasets import DatasetDict, concatenate_datasets, load_dataset\n",
    "from huggingface_hub import Repository, create_repo\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import transformers\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Finetune a transformers model on a text classification task\")\n",
    "    parser.add_argument(\n",
    "        \"--dataset_name\",\n",
    "        type=str,\n",
    "        default='librispeech_asr',\n",
    "        help=\"The name of the dataset to use (via the datasets library).\",\n",
    "    )\n",
    "    parser.add_argument('--range', nargs='+', type=str, default=['clean, clean'], help='specify a range')\n",
    "    parser.add_argument(\n",
    "        \"--dataset_config_names\",\n",
    "        nargs='+',\n",
    "        type=str,\n",
    "        default = ['clean', 'clean'],\n",
    "        # required=True,\n",
    "        help=\"The configuration names of the dataset to use (via the datasets library).\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--dataset_split_names\",\n",
    "        nargs=\"+\",\n",
    "        type=str,\n",
    "        default = ['validation', 'test'],\n",
    "        # required=True,\n",
    "        help=\"The names of the training data set splits to use (via the datasets library).\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--preprocessing_num_workers\",\n",
    "        type=int,\n",
    "        default=None,\n",
    "        help=\"The number of processes to use for the preprocessing.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--overwrite_cache\", action=\"store_true\", help=\"Overwrite the cached training and evaluation sets\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--preprocessing_only\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Only run the preprocessing script to be cached for future use\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--cache_dir\",\n",
    "        type=str,\n",
    "        default=None,\n",
    "        help=\"Where do you want to store the pretrained models downloaded from huggingface.co\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--validation_split_percentage\",\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help=\"Percentage of training data that should be used for validation if no validation is present in dataset.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--logging_steps\",\n",
    "        type=int,\n",
    "        default=500,\n",
    "        help=\"Number of steps between each logging\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--saving_steps\",\n",
    "        type=int,\n",
    "        default=500,\n",
    "        help=\"Number of steps between each logging\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--audio_column_name\",\n",
    "        type=str,\n",
    "        default=\"audio\",\n",
    "        help=\"Column in the dataset that contains speech file path. Defaults to 'audio'\",\n",
    "    )\n",
    "    # parser.add_argument(\n",
    "    #     \"--model_name_or_path\",\n",
    "    #     type=str,\n",
    "    #     help=\"Path to pretrained model or model identifier from huggingface.co/models.\",\n",
    "    #     required=True,\n",
    "    # )\n",
    "    parser.add_argument(\n",
    "        \"--config_name\",\n",
    "        type=str,\n",
    "        default=None,\n",
    "        help=\"Pretrained config name or path if not the same as model_name\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--train_cache_file_name\",\n",
    "        type=str,\n",
    "        default=None,\n",
    "        help=\"Path to the train cached file name\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--validation_cache_file_name\",\n",
    "        type=str,\n",
    "        default=None,\n",
    "        help=\"Path to the validation cached file name\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--per_device_train_batch_size\",\n",
    "        type=int,\n",
    "        default=8,\n",
    "        help=\"Batch size (per device) for the training dataloader.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--per_device_eval_batch_size\",\n",
    "        type=int,\n",
    "        default=8,\n",
    "        help=\"Batch size (per device) for the evaluation dataloader.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--learning_rate\",\n",
    "        type=float,\n",
    "        default=5e-5,\n",
    "        help=\"Initial learning rate (after the potential warmup period) to use.\",\n",
    "    )\n",
    "    parser.add_argument(\"--weight_decay\", type=float, default=0.0, help=\"Weight decay to use.\")\n",
    "    parser.add_argument(\"--num_train_epochs\", type=int, default=3, help=\"Total number of training epochs to perform.\")\n",
    "    parser.add_argument(\n",
    "        \"--max_train_steps\",\n",
    "        type=int,\n",
    "        default=None,\n",
    "        help=\"Total number of training steps to perform. If provided, overrides num_train_epochs.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--gradient_accumulation_steps\",\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--gradient_checkpointing\",\n",
    "        action=\"store_true\",\n",
    "        help=\"If True, use gradient checkpointing to save memory at the expense of slower backward pass.\",\n",
    "    )\n",
    "    # parser.add_argument(\n",
    "    #     \"--lr_scheduler_type\",\n",
    "    #     type=SchedulerType,\n",
    "    #     default=\"linear\",\n",
    "    #     help=\"The scheduler type to use.\",\n",
    "    #     choices=[\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\"],\n",
    "    # )\n",
    "    parser.add_argument(\n",
    "        \"--num_warmup_steps\", type=int, default=0, help=\"Number of steps for the warmup in the lr scheduler.\"\n",
    "    )\n",
    "    parser.add_argument(\"--output_dir\", type=str, default=None, help=\"Where to store the final model.\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=0, help=\"A seed for reproducible training.\")\n",
    "    parser.add_argument(\n",
    "        \"--max_gumbel_temperature\",\n",
    "        type=float,\n",
    "        default=2.0,\n",
    "        help=\"Maximum temperature for gumbel softmax.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--min_gumbel_temperature\",\n",
    "        type=float,\n",
    "        default=0.5,\n",
    "        help=\"Minimum temperature for gumbel softmax.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--gumbel_temperature_decay\", type=float, default=0.999995, help=\"Decay of gumbel temperature during training.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_duration_in_seconds\",\n",
    "        type=float,\n",
    "        default=5.0,\n",
    "        help=\"Filter out audio files that are longer than `max_duration_in_seconds` seconds\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--min_duration_in_seconds\",\n",
    "        type=float,\n",
    "        default=3.0,\n",
    "        help=\"Filter out audio files that are shorter than `min_duration_in_seconds` seconds\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--pad_to_multiple_of\",\n",
    "        type=int,\n",
    "        default=None,\n",
    "        help=(\n",
    "            \"If set will pad the sequence to a multiple of the provided value. This is especially useful to enable the\"\n",
    "            \" use of Tensor Cores on NVIDIA hardware with compute capability >= 7.5 (Volta).\"\n",
    "        ),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--adam_beta1\",\n",
    "        type=float,\n",
    "        default=0.9,\n",
    "        help=\"Beta1 for AdamW optimizer\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--adam_beta2\",\n",
    "        type=float,\n",
    "        default=0.999,\n",
    "        help=\"Beta2 for AdamW optimizer\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--adam_epsilon\",\n",
    "        type=float,\n",
    "        default=1e-8,\n",
    "        help=\"Epsilon for AdamW optimizer\",\n",
    "    )\n",
    "    parser.add_argument(\"--push_to_hub\", default=False, action=\"store_false\", help=\"Whether or not to push the model to the Hub.\")\n",
    "    parser.add_argument(\n",
    "        \"--hub_model_id\", type=str, help=\"The name of the repository to keep in sync with the local `output_dir`.\"\n",
    "    )\n",
    "    parser.add_argument(\"--hub_token\", type=str, help=\"The token to use to push to the Model Hub.\")\n",
    "    parser.add_argument(\n",
    "        \"--mask_time_prob\",\n",
    "        type=float,\n",
    "        default=None,\n",
    "        help=(\n",
    "            \"Percentage (between 0 and 1) of all feature vectors along the time axis which will be masked in the\"\n",
    "            \" contrastive task. If omitted, will pull value from model config.\"\n",
    "        ),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--mask_time_length\",\n",
    "        type=int,\n",
    "        default=None,\n",
    "        help=(\n",
    "            \"Length of each vector mask span to mask along the time axis in the contrastive task.\"\n",
    "            \" If omitted, will pull value from model config.\"\n",
    "        ),\n",
    "    )\n",
    "    # args = parser.parse_args()\n",
    "    args = parser.parse_known_args()[0]\n",
    "\n",
    "    if args.push_to_hub:\n",
    "        print('TTTTT')\n",
    "        assert args.output_dir is not None, \"Need an `output_dir` to create a repo when `--push_to_hub` is passed.\"\n",
    "\n",
    "    if args.output_dir is not None:\n",
    "        os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args()\n",
    "\n",
    "print(args.dataset_config_names)\n",
    "print(args.dataset_split_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the accelerator. We will let the accelerator handle device placement for us in this example.\n",
    "accelerator = Accelerator()\n",
    "logger.info(accelerator.state, main_process_only=False)\n",
    "if accelerator.is_local_main_process:\n",
    "    datasets.utils.logging.set_verbosity_warning()\n",
    "    transformers.utils.logging.set_verbosity_info()\n",
    "\n",
    "    # set up weights and biases if available\n",
    "    if is_wandb_available():\n",
    "        import wandb\n",
    "\n",
    "        wandb.init(project=args.output_dir.split(\"/\")[-1])\n",
    "else:\n",
    "    datasets.utils.logging.set_verbosity_error()\n",
    "    transformers.utils.logging.set_verbosity_error()\n",
    "\n",
    "# If passed along, set the training seed now.\n",
    "if args.seed is not None:\n",
    "    set_seed(args.seed)\n",
    "\n",
    "# Handle the repository creation\n",
    "if accelerator.is_main_process:\n",
    "    if args.push_to_hub and not args.preprocessing_only:\n",
    "        # Retrieve of infer repo_name\n",
    "        repo_name = args.hub_model_id\n",
    "        if repo_name is None:\n",
    "            repo_name = Path(args.output_dir).absolute().name\n",
    "        # Create repo and retrieve repo_id\n",
    "        repo_id = create_repo(repo_name, exist_ok=True, token=args.hub_token).repo_id\n",
    "        # Clone repo locally\n",
    "        repo = Repository(args.output_dir, clone_from=repo_id, token=args.hub_token)\n",
    "    elif args.output_dir is not None:\n",
    "        os.makedirs(args.output_dir, exist_ok=True)\n",
    "accelerator.wait_for_everyone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Download and create train, validation dataset\n",
    "# We load all dataset configuration and datset split pairs passed in\n",
    "# ``args.dataset_config_names`` and ``args.dataset_split_names``\n",
    "datasets_splits = []\n",
    "for dataset_config_name, train_split_name in zip(args.dataset_config_names, args.dataset_split_names):\n",
    "    # load dataset\n",
    "    dataset_split = load_dataset(\n",
    "        args.dataset_name,\n",
    "        dataset_config_name,\n",
    "        split=train_split_name,\n",
    "        cache_dir=args.cache_dir,\n",
    "    )\n",
    "    datasets_splits.append(dataset_split)\n",
    "\n",
    "# Next, we concatenate all configurations and splits into a single training dataset\n",
    "raw_datasets = DatasetDict()\n",
    "if len(datasets_splits) > 1:\n",
    "    raw_datasets = concatenate_datasets(datasets_splits).shuffle(seed=args.seed)\n",
    "else:\n",
    "    raw_datasets = datasets_splits[0]\n",
    "\n",
    "# Take ``args.validation_split_percentage`` from the training dataset for the validation_split_percentage\n",
    "num_validation_samples = raw_datasets[\"train\"].num_rows * args.validation_split_percentage // 100\n",
    "\n",
    "if num_validation_samples == 0:\n",
    "    raise ValueError(\n",
    "        \"`args.validation_split_percentage` is less than a single sample \"\n",
    "        f\"for {len(raw_datasets['train'])} training samples. Increase \"\n",
    "        \"`args.num_validation_split_percentage`. \"\n",
    "    )\n",
    "\n",
    "raw_datasets[\"validation\"] = raw_datasets[\"train\"].select(range(num_validation_samples))\n",
    "raw_datasets[\"train\"] = raw_datasets[\"train\"].select(range(num_validation_samples, raw_datasets[\"train\"].num_rows))\n",
    "\n",
    "# 2. Now we preprocess the datasets including loading the audio, resampling and normalization\n",
    "# Thankfully, `datasets` takes care of automatically loading and resampling the audio,\n",
    "# so that we just need to set the correct target sampling rate and normalize the input\n",
    "# via the `feature_extractor`\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(args.model_name_or_path)\n",
    "\n",
    "# make sure that dataset decodes audio with correct sampling rate\n",
    "raw_datasets = raw_datasets.cast_column(\n",
    "    args.audio_column_name, datasets.features.Audio(sampling_rate=feature_extractor.sampling_rate)\n",
    ")\n",
    "\n",
    "# only normalized-inputs-training is supported\n",
    "if not feature_extractor.do_normalize:\n",
    "    raise ValueError(\n",
    "        \"Training is only supported for normalized inputs. Make sure ``feature_extractor.do_normalize == True``\"\n",
    "    )\n",
    "\n",
    "# set max & min audio length in number of samples\n",
    "max_length = int(args.max_duration_in_seconds * feature_extractor.sampling_rate)\n",
    "min_length = int(args.min_duration_in_seconds * feature_extractor.sampling_rate)\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    sample = batch[args.audio_column_name]\n",
    "\n",
    "    inputs = feature_extractor(\n",
    "        sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], max_length=max_length, truncation=True\n",
    "    )\n",
    "    batch[\"input_values\"] = inputs.input_values[0]\n",
    "    batch[\"input_length\"] = len(inputs.input_values[0])\n",
    "\n",
    "    return batch\n",
    "\n",
    "# load via mapped files via path\n",
    "cache_file_names = None\n",
    "if args.train_cache_file_name is not None:\n",
    "    cache_file_names = {\"train\": args.train_cache_file_name, \"validation\": args.validation_cache_file_name}\n",
    "\n",
    "# load audio files into numpy arrays\n",
    "with accelerator.main_process_first():\n",
    "    vectorized_datasets = raw_datasets.map(\n",
    "        prepare_dataset,\n",
    "        num_proc=args.preprocessing_num_workers,\n",
    "        remove_columns=raw_datasets[\"train\"].column_names,\n",
    "        cache_file_names=cache_file_names,\n",
    "    )\n",
    "\n",
    "    if min_length > 0.0:\n",
    "        vectorized_datasets = vectorized_datasets.filter(\n",
    "            lambda x: x > min_length,\n",
    "            num_proc=args.preprocessing_num_workers,\n",
    "            input_columns=[\"input_length\"],\n",
    "        )\n",
    "\n",
    "    vectorized_datasets = vectorized_datasets.remove_columns(\"input_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_scratch = False\n",
    "\n",
    "if from_scratch:\n",
    "    ## If we want to train the model from scratch\n",
    "    # 3. Load model\n",
    "    config = Wav2Vec2Config.from_pretrained(args.model_name_or_path)\n",
    "\n",
    "    # pretraining is only supported for \"newer\" stable layer norm architecture\n",
    "    # apply_spec_augment has to be True, mask_feature_prob has to be 0.0\n",
    "    if not config.do_stable_layer_norm or config.feat_extract_norm != \"layer\":\n",
    "        raise ValueError(\n",
    "            \"PreTraining is only supported for ``config.do_stable_layer_norm=True`` and\"\n",
    "            \" ``config.feat_extract_norm='layer'\"\n",
    "        )\n",
    "\n",
    "    # initialize random model\n",
    "    model = Wav2Vec2ForPreTraining(config)\n",
    "\n",
    "else:\n",
    "    ## If we want to train the model using any pre-trained weights\n",
    "    model = Wav2Vec2ForPreTrainingfrom_pretrained(args.model_name_or_path)\n",
    "\n",
    "# Activate gradient checkpointing if needed\n",
    "if args.gradient_checkpointing:\n",
    "    model.gradient_checkpointing_enable()\n",
    "\n",
    "# 4. Define data collator, optimizer and scheduler\n",
    "\n",
    "mask_time_prob = config.mask_time_prob if args.mask_time_prob is None else args.mask_time_prob\n",
    "mask_time_length = config.mask_time_length if args.mask_time_length is None else args.mask_time_length\n",
    "\n",
    "data_collator = DataCollatorForWav2Vec2Pretraining(\n",
    "    model=model,\n",
    "    feature_extractor=feature_extractor,\n",
    "    pad_to_multiple_of=args.pad_to_multiple_of,\n",
    "    mask_time_prob=mask_time_prob,\n",
    "    mask_time_length=mask_time_length,\n",
    ")\n",
    "train_dataloader = DataLoader(\n",
    "    vectorized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=args.per_device_train_batch_size,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    vectorized_datasets[\"validation\"], collate_fn=data_collator, batch_size=args.per_device_eval_batch_size\n",
    ")\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(\n",
    "    list(model.parameters()),\n",
    "    lr=args.learning_rate,\n",
    "    betas=[args.adam_beta1, args.adam_beta2],\n",
    "    eps=args.adam_epsilon,\n",
    ")\n",
    "\n",
    "# Prepare everything with our `accelerator`.\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")\n",
    "\n",
    "# Scheduler and math around the number of training steps.\n",
    "num_update_steps_per_epoch = math.ceil(len(train_dataloader) / args.gradient_accumulation_steps)\n",
    "\n",
    "if args.max_train_steps is None:\n",
    "    args.max_train_steps = args.num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=args.lr_scheduler_type,\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=args.num_warmup_steps,\n",
    "    num_training_steps=args.max_train_steps,\n",
    ")\n",
    "\n",
    "# Afterwards we recalculate our number of training epochs\n",
    "args.num_train_epochs = math.ceil(args.max_train_steps / num_update_steps_per_epoch)\n",
    "\n",
    "# 5. Train\n",
    "total_batch_size = args.per_device_train_batch_size * accelerator.num_processes * args.gradient_accumulation_steps\n",
    "\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(f\"  Num examples = {len(vectorized_datasets['train'])}\")\n",
    "logger.info(f\"  Num Epochs = {args.num_train_epochs}\")\n",
    "logger.info(f\"  Instantaneous batch size per device = {args.per_device_train_batch_size}\")\n",
    "logger.info(f\"  Total train batch size (w. parallel, distributed & accumulation) = {total_batch_size}\")\n",
    "logger.info(f\"  Gradient Accumulation steps = {args.gradient_accumulation_steps}\")\n",
    "logger.info(f\"  Total optimization steps = {args.max_train_steps}\")\n",
    "completed_steps = 0\n",
    "starting_epoch = 0\n",
    "\n",
    "# Only show the progress bar once on each machine.\n",
    "progress_bar = tqdm(range(args.max_train_steps), disable=not accelerator.is_local_main_process)\n",
    "completed_steps = 0\n",
    "starting_epoch = 0\n",
    "for epoch in range(starting_epoch, args.num_train_epochs):\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # compute num of losses\n",
    "        num_losses = batch[\"mask_time_indices\"].sum()\n",
    "        sub_attention_mask = batch.pop(\"sub_attention_mask\", None)\n",
    "        sub_attention_mask = (\n",
    "            sub_attention_mask if sub_attention_mask is not None else torch.ones_like(batch[\"mask_time_indices\"])\n",
    "        )\n",
    "        percent_masked = num_losses / sub_attention_mask.sum()\n",
    "\n",
    "        # forward\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        # divide loss by gradient accumulation steps since gradients\n",
    "        # are accumulated for multiple backward passes in PyTorch\n",
    "        loss = outputs.loss / args.gradient_accumulation_steps\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        # make sure that `num_losses` is summed for distributed training\n",
    "        # and average gradients over losses of all devices\n",
    "        if accelerator.state.num_processes > 1:\n",
    "            num_losses = accelerator.gather_for_metrics(num_losses).sum()\n",
    "            gradient_multiplier = accelerator.state.num_processes / num_losses\n",
    "            multiply_grads(model.module.parameters(), gradient_multiplier)\n",
    "        else:\n",
    "            multiply_grads(model.parameters(), 1 / num_losses)\n",
    "\n",
    "        # update step\n",
    "        if (step + 1) % args.gradient_accumulation_steps == 0 or step == len(train_dataloader) - 1:\n",
    "            # compute grad norm for monitoring\n",
    "            scale = (\n",
    "                accelerator.scaler._scale.item()\n",
    "                if hasattr(accelerator, \"scaler\") and accelerator.scaler is not None\n",
    "                else 1\n",
    "            )\n",
    "            if accelerator.state.num_processes > 1:\n",
    "                grad_norm = get_grad_norm(model.module.parameters(), scale)\n",
    "            else:\n",
    "                grad_norm = get_grad_norm(model.parameters(), scale)\n",
    "\n",
    "            # update parameters\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if not accelerator.optimizer_step_was_skipped:\n",
    "                lr_scheduler.step()\n",
    "            elif accelerator.is_local_main_process:\n",
    "                progress_bar.write(\n",
    "                    f\"Gradients have overflown - skipping update step... Updating gradient scale to {scale}...\"\n",
    "                )\n",
    "\n",
    "            # update gumbel temperature\n",
    "            gumbel_temperature = max(\n",
    "                args.max_gumbel_temperature * args.gumbel_temperature_decay**completed_steps,\n",
    "                args.min_gumbel_temperature,\n",
    "            )\n",
    "            if hasattr(model, \"module\"):\n",
    "                model.module.set_gumbel_temperature(gumbel_temperature)\n",
    "            else:\n",
    "                model.set_gumbel_temperature(gumbel_temperature)\n",
    "\n",
    "            progress_bar.update(1)\n",
    "            completed_steps += 1\n",
    "\n",
    "        # 6. Log all results\n",
    "        if (step + 1) % (args.gradient_accumulation_steps * args.logging_steps) == 0:\n",
    "            loss.detach()\n",
    "            outputs.contrastive_loss.detach()\n",
    "            outputs.diversity_loss.detach()\n",
    "\n",
    "            if accelerator.state.num_processes > 1:\n",
    "                loss = accelerator.gather_for_metrics(loss).sum()\n",
    "                outputs.contrastive_loss = accelerator.gather_for_metrics(outputs.contrastive_loss).sum()\n",
    "                outputs.diversity_loss = accelerator.gather_for_metrics(outputs.diversity_loss).sum()\n",
    "                percent_masked = accelerator.gather_for_metrics(percent_masked).sum()\n",
    "\n",
    "            train_logs = {\n",
    "                \"loss\": (loss * args.gradient_accumulation_steps) / num_losses,\n",
    "                \"constrast_loss\": outputs.contrastive_loss / num_losses,\n",
    "                \"div_loss\": outputs.diversity_loss / num_losses,\n",
    "                \"%_mask_idx\": percent_masked / accelerator.num_processes,\n",
    "                \"ppl\": outputs.codevector_perplexity,\n",
    "                \"lr\": torch.tensor(optimizer.param_groups[0][\"lr\"]),\n",
    "                \"temp\": torch.tensor(gumbel_temperature),\n",
    "                \"grad_norm\": torch.tensor(grad_norm),\n",
    "            }\n",
    "            log_str = \"\"\n",
    "            for k, v in train_logs.items():\n",
    "                log_str += \"| {}: {:.3e}\".format(k, v.item())\n",
    "\n",
    "            if accelerator.is_local_main_process:\n",
    "                progress_bar.write(log_str)\n",
    "                if is_wandb_available():\n",
    "                    wandb.log(train_logs)\n",
    "\n",
    "        # save model every `args.saving_steps` steps\n",
    "        if (step + 1) % (args.gradient_accumulation_steps * args.saving_steps) == 0:\n",
    "            if (args.push_to_hub and epoch < args.num_train_epochs - 1) or args.output_dir is not None:\n",
    "                accelerator.wait_for_everyone()\n",
    "                unwrapped_model = accelerator.unwrap_model(model)\n",
    "                unwrapped_model.save_pretrained(\n",
    "                    args.output_dir, is_main_process=accelerator.is_main_process, save_function=accelerator.save\n",
    "                )\n",
    "\n",
    "            if (args.push_to_hub and epoch < args.num_train_epochs - 1) and accelerator.is_main_process:\n",
    "                repo.push_to_hub(\n",
    "                    commit_message=f\"Training in progress step {completed_steps}\",\n",
    "                    blocking=False,\n",
    "                    auto_lfs_prune=True,\n",
    "                )\n",
    "\n",
    "        # if completed steps > `args.max_train_steps` stop\n",
    "        if completed_steps >= args.max_train_steps:\n",
    "            break\n",
    "\n",
    "    # 7. Validate!\n",
    "    model.eval()\n",
    "\n",
    "    # init logs\n",
    "    val_logs = {\n",
    "        \"val_loss\": 0,\n",
    "        \"val_contrastive_loss\": 0,\n",
    "        \"val_diversity_loss\": 0,\n",
    "        \"val_num_losses\": 0,\n",
    "    }\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            batch.pop(\"sub_attention_mask\", None)\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        val_logs[\"val_loss\"] += outputs.loss\n",
    "        val_logs[\"val_contrastive_loss\"] += outputs.contrastive_loss\n",
    "        val_logs[\"val_diversity_loss\"] += outputs.diversity_loss\n",
    "        val_logs[\"val_num_losses\"] += batch[\"mask_time_indices\"].sum()\n",
    "\n",
    "    # sum over devices in multi-processing\n",
    "    if accelerator.num_processes > 1:\n",
    "        val_logs = {k: accelerator.gather_for_metrics(v).sum() for k, v in val_logs.items()}\n",
    "\n",
    "    val_logs = {k: v / val_logs[\"val_num_losses\"] for k, v in val_logs.items()}\n",
    "\n",
    "    log_str = \"\"\n",
    "    for k, v in val_logs.items():\n",
    "        log_str += \"| {}: {:.3e}\".format(k, v.item())\n",
    "\n",
    "    if accelerator.is_local_main_process:\n",
    "        progress_bar.write(log_str)\n",
    "        if is_wandb_available():\n",
    "            wandb.log(val_logs)\n",
    "\n",
    "    if args.output_dir is not None:\n",
    "        accelerator.wait_for_everyone()\n",
    "        unwrapped_model = accelerator.unwrap_model(model)\n",
    "        unwrapped_model.save_pretrained(\n",
    "            args.output_dir, is_main_process=accelerator.is_main_process, save_function=accelerator.save\n",
    "        )\n",
    "        if accelerator.is_main_process:\n",
    "            if args.push_to_hub:\n",
    "                repo.push_to_hub(commit_message=\"End of training\", auto_lfs_prune=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
